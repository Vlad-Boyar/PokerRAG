import os
import pandas as pd
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, ContextTypes,
    CommandHandler, MessageHandler, filters
)
from llama_index.core import VectorStoreIndex, Settings, Document
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –∏ —ç–º–±–µ–¥–¥–µ—Ä–∞
Settings.llm = OpenAI(model="gpt-3.5-turbo", api_key=OPENAI_API_KEY)
Settings.embed_model = HuggingFaceEmbedding(
    model_name="intfloat/multilingual-e5-base",
    embed_batch_size=8,
    query_instruction="query:",
    text_instruction="passage:"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã
def load_documents_from_csv(csv_path="faq.csv"):
    df = pd.read_csv(csv_path)
    return [Document(text=f"Q: {row['question']}\nA: {row['answer']}") for _, row in df.iterrows()]

documents = load_documents_from_csv()
index = VectorStoreIndex.from_documents(documents)
retriever = index.as_retriever(similarity_top_k=3)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text
    print(f"[RAG] –í–æ–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}")
    nodes = retriever.retrieve(query)

    if not nodes or (nodes[0].score or 0.0) < 0.5:
        await update.message.reply_text("‚ùå –ù–µ –Ω–∞—à—ë–ª —É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.")
        return

    context_str = nodes[0].get_content()
    prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context_str}\n\n–í–æ–ø—Ä–æ—Å: {query}\n–û—Ç–≤–µ—Ç:"
    response = Settings.llm.complete(prompt).text.strip()

    explanation = "üîç –ü–æ—Ö–æ–∂–∏–µ –≤–æ–ø—Ä–æ—Å—ã:\n"
    for i, node in enumerate(nodes[:3]):
        question_line = node.get_content().split("\n")[0].replace("Q: ", "").strip()
        explanation += f"{i+1}. {question_line}  ‚Äî  üìä {node.score:.2f}\n"

    await update.message.reply_text(f"{response}\n\n{explanation}")

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –≤ –±–∞–∑–µ.")

# üëá –ó–∞–ø—É—Å–∫ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ run_polling()
if __name__ == "__main__":
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –∂–¥—ë—Ç –≤–æ–ø—Ä–æ—Å–æ–≤.")
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle))
    app.run_polling()  # <--- sync –≤—ã–∑–æ–≤, –≤—Å—ë –æ–∫ –¥–∞–∂–µ –µ—Å–ª–∏ loop —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
