from llama_index.core import VectorStoreIndex, Document, Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from dotenv import load_dotenv
import pandas as pd
import os

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    raise ValueError("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω!")

# –ó–∞–≥—Ä—É–∑–∫–∞ CSV
df = pd.read_csv("faq.csv")

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã
documents = [
    Document(text=row["answer"], metadata={"question": row["question"]})
    for _, row in df.iterrows()
]

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
Settings.llm = OpenAI(model="gpt-3.5-turbo", temperature=0)
Settings.embed_model = OpenAIEmbedding()

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
index = VectorStoreIndex.from_documents(documents)

# –ó–∞–ø—É—Å–∫ query engine
query_engine = index.as_query_engine()

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
print("ü§ñ –í–≤–µ–¥–∏ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):")
while True:
    user_input = input("‚ùì ")
    if user_input.lower() in ("exit", "quit"):
        break
    response = query_engine.query(user_input)
    print("üí¨", response)
